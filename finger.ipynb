{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:50:02.118763Z",
     "start_time": "2020-08-26T16:49:59.646205Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:50:16.907854Z",
     "start_time": "2020-08-26T16:50:16.905854Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train_dir = 'D:/Desktop/Itwill ws/shiny_project/fingers/train/'\n",
    "data_test_dir = 'D:/Desktop/Itwill ws/shiny_project/fingers/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:50:17.161921Z",
     "start_time": "2020-08-26T16:50:17.159921Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = 'D:/Desktop/Itwill ws/shiny_project/working/train_dir'\n",
    "val_dir = 'D:/Desktop/Itwill ws/shiny_project/working/val_dir'\n",
    "test_dir = 'D:/Desktop/Itwill ws/shiny_project/working/test_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:12:26.130446Z",
     "start_time": "2020-08-26T16:12:26.126445Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_directory(dir_name):\n",
    "    dirs = [os.path.join(dir_name, \"L\"), os.path.join(dir_name, \"R\")]\n",
    "    \n",
    "    if os.path.exists(dir_name):\n",
    "        shutil.rmtree(dir_name)\n",
    "    os.makedirs(dir_name)\n",
    "    \n",
    "    for dir in dirs:\n",
    "        for i in range(6):\n",
    "            os.makedirs(dir + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:12:26.281477Z",
     "start_time": "2020-08-26T16:12:26.273476Z"
    }
   },
   "outputs": [],
   "source": [
    "create_directory(train_dir)\n",
    "create_directory(val_dir)\n",
    "create_directory(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:12:27.123752Z",
     "start_time": "2020-08-26T16:12:27.120760Z"
    }
   },
   "outputs": [],
   "source": [
    "paths_train = []\n",
    "paths_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:12:29.880116Z",
     "start_time": "2020-08-26T16:12:29.878108Z"
    }
   },
   "outputs": [],
   "source": [
    "count_data = {'0L': 0,\n",
    "              '1L': 0,\n",
    "              '2L': 0,\n",
    "              '3L': 0,\n",
    "              '4L': 0,\n",
    "              '5L': 0,\n",
    "              '0R': 0,\n",
    "              '1R': 0,\n",
    "              '2R': 0,\n",
    "              '3R': 0,\n",
    "              '4R': 0,\n",
    "              '5R': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:13:17.202664Z",
     "start_time": "2020-08-26T16:13:17.124646Z"
    }
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk(data_train_dir):\n",
    "    for filename in filenames:\n",
    "        paths_train.append(os.path.join(dirname, filename))\n",
    "        \n",
    "for dirname, _, filenames in os.walk(data_test_dir):\n",
    "    for filename in filenames:\n",
    "        paths_test.append(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:13:34.228471Z",
     "start_time": "2020-08-26T16:13:34.190470Z"
    }
   },
   "outputs": [],
   "source": [
    "for filename in paths_train:\n",
    "    for key in count_data.keys():\n",
    "        if filename[-6:-4] == key:\n",
    "            count_data[key] += 1\n",
    "            \n",
    "for filename in paths_test:\n",
    "    for key in count_data.keys():\n",
    "        if filename[-6:-4] == key:\n",
    "            count_data[key] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:13:38.952699Z",
     "start_time": "2020-08-26T16:13:38.950705Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = count_data.values()\n",
    "groups = count_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:14:27.616564Z",
     "start_time": "2020-08-26T16:14:27.613563Z"
    }
   },
   "outputs": [],
   "source": [
    "def copy_images(start_index, end_index, paths, dest_dir):\n",
    "    for i in range(start_index, end_index):\n",
    "        dest_path = os.path.join(dest_dir, paths[i][-5] + paths[i][-6])\n",
    "        shutil.copy2(paths[i], dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:50:22.772982Z",
     "start_time": "2020-08-26T16:50:22.769990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Part of the validation data set\n",
    "validation_data_proportion = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:14:48.584728Z",
     "start_time": "2020-08-26T16:14:29.264367Z"
    }
   },
   "outputs": [],
   "source": [
    "# copying images from input directory to output\n",
    "copy_images(0, len(paths_train) - int(validation_data_proportion * len(paths_train)),\n",
    "            paths_train, train_dir)\n",
    "copy_images(len(paths_train) - int(validation_data_proportion * len(paths_train)),\n",
    "            len(paths_train), paths_train, val_dir)\n",
    "copy_images(0, len(paths_test), paths_test, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:49:50.204396Z",
     "start_time": "2020-08-26T16:49:50.202395Z"
    }
   },
   "outputs": [],
   "source": [
    "target_size = (90, 90)\n",
    "batch_size = 50\n",
    "mode = 'categorical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:50:10.396414Z",
     "start_time": "2020-08-26T16:50:10.393420Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:50:30.084292Z",
     "start_time": "2020-08-26T16:50:29.512155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15300 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = datagen.flow_from_directory(train_dir,\n",
    "                                       target_size=target_size,\n",
    "                                       batch_size=batch_size,\n",
    "                                       class_mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:50:31.209514Z",
     "start_time": "2020-08-26T16:50:31.097488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2700 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "val_gen = datagen.flow_from_directory(val_dir,\n",
    "                                       target_size=target_size,\n",
    "                                       batch_size=batch_size,\n",
    "                                       class_mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:50:32.586149Z",
     "start_time": "2020-08-26T16:50:32.366103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3600 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = datagen.flow_from_directory(test_dir,\n",
    "                                       target_size=target_size,\n",
    "                                       batch_size=batch_size,\n",
    "                                       class_mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:50:34.499321Z",
     "start_time": "2020-08-26T16:50:34.495320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L0': 0,\n",
       " 'L1': 1,\n",
       " 'L2': 2,\n",
       " 'L3': 3,\n",
       " 'L4': 4,\n",
       " 'L5': 5,\n",
       " 'R0': 6,\n",
       " 'R1': 7,\n",
       " 'R2': 8,\n",
       " 'R3': 9,\n",
       " 'R4': 10,\n",
       " 'R5': 11}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:51:35.252018Z",
     "start_time": "2020-08-26T16:51:35.249018Z"
    }
   },
   "outputs": [],
   "source": [
    "len_train_data = len(train_gen.filenames)\n",
    "len_test_data = len(test_gen.filenames)\n",
    "len_val_data = len(val_gen.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:50:51.290769Z",
     "start_time": "2020-08-26T16:50:51.287480Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model_path = 'best_model.h5'\n",
    "checkpoint_callback = ModelCheckpoint(best_model_path,\n",
    "                                     monitor='val_accuracy',\n",
    "                                     save_best_only=True,\n",
    "                                     verbose=1)\n",
    "reduce_callback = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                   patience=3,\n",
    "                                   factor=0.5,\n",
    "                                   min_lr=0.00001,\n",
    "                                   verbose=1)\n",
    "callbacks_list = [checkpoint_callback, reduce_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:50:54.391947Z",
     "start_time": "2020-08-26T16:50:52.995627Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(90, 90, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:50:55.465032Z",
     "start_time": "2020-08-26T16:50:55.461040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 88, 88, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 86, 86, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 41, 41, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 39, 39, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 46208)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               11829504  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 12,092,748\n",
      "Trainable params: 12,092,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:51:05.038538Z",
     "start_time": "2020-08-26T16:51:04.975524Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='RMSprop',\n",
    "             metrics=['accuracy', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:53:16.680574Z",
     "start_time": "2020-08-26T16:51:38.670355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-01baad38fcad>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 306 steps, validate for 54 steps\n",
      "Epoch 1/3\n",
      "305/306 [============================>.] - ETA: 0s - loss: 0.2627 - accuracy: 0.9279 - AUC: 0.9946 ETA: 0s - loss: 0.2684 - accuracy: 0.9264\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.99926, saving model to best_model.h5\n",
      "306/306 [==============================] - 36s 117ms/step - loss: 0.2618 - accuracy: 0.9281 - AUC: 0.9946 - val_loss: 0.0021 - val_accuracy: 0.9993 - val_AUC: 1.0000\n",
      "Epoch 2/3\n",
      "305/306 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9982 - AUC: 0.9998\n",
      "Epoch 00002: val_accuracy improved from 0.99926 to 1.00000, saving model to best_model.h5\n",
      "306/306 [==============================] - 31s 101ms/step - loss: 0.0061 - accuracy: 0.9982 - AUC: 0.9998 - val_loss: 2.8234e-06 - val_accuracy: 1.0000 - val_AUC: 1.0000\n",
      "Epoch 3/3\n",
      "305/306 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9984 - AUC: 0.9996\n",
      "Epoch 00003: val_accuracy did not improve from 1.00000\n",
      "306/306 [==============================] - 31s 102ms/step - loss: 0.0109 - accuracy: 0.9984 - AUC: 0.9996 - val_loss: 1.4570e-09 - val_accuracy: 1.0000 - val_AUC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                   steps_per_epoch=len_train_data // batch_size,\n",
    "                   epochs=3,\n",
    "                   validation_data=val_gen,\n",
    "                   validation_steps=len_val_data // batch_size,\n",
    "                   verbose=1,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:53:23.411267Z",
     "start_time": "2020-08-26T16:53:23.366256Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:53:27.945144Z",
     "start_time": "2020-08-26T16:53:24.823439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-836c64de6c24>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 6.9658e-04 - accuracy: 0.9994 - AUC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "testing_model = model.evaluate_generator(test_gen, len_test_data // batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T16:53:31.133218Z",
     "start_time": "2020-08-26T16:53:31.131217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of correct responses: 99.94%\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of correct responses: ' + str(int(testing_model[1] * 10000) / 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.datasets import cifar10\n",
    "#from keras.models import Sequential, save_model\n",
    "#from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "#from keras.layers import Conv2D, MaxPooling2D\n",
    "#import numpy as np\n",
    "#from keras.utils import np_utils\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "# 필요한 모듈을 임폴트 한다. \n",
    "import loader3\n",
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Activation\n",
    "\n",
    "# 하이퍼 파라미터를 설정한다. \n",
    "batch_size = 28\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    " \n",
    "# 이미지 데이터와 라벨위치 \n",
    "train_image = 'D:\\\\data\\\\leafs\\\\images\\\\train_resize\\\\'\n",
    "test_image = 'D:\\\\data\\\\leafs\\\\images\\\\test_resize\\\\'\n",
    "train_label = 'D:\\\\data\\\\leafs\\\\images\\\\train_label.csv'\n",
    "test_label = 'D:\\\\data\\\\leafs\\\\images\\\\test_label.csv'\n",
    "\n",
    "# 데이터 로드 \n",
    "x_train = loader3.image_load(train_image)\n",
    "y_train = loader3.label_load(train_label)\n",
    "x_test = loader3.image_load(test_image)\n",
    "y_test = loader3.label_load(test_label)      \n",
    "\n",
    "print ( loader3.image_load(train_image).shape )\n",
    "print ( loader3.image_load(test_image).shape )\n",
    "print ( loader3.label_load(train_label).shape)\n",
    "print ( loader3.label_load(test_label).shape )\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# One hot Encoding\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# 모델 구성 \n",
    "model = Sequential()\n",
    "# 첫번째 층은 반드시 input_shape 를 지정해야한다. \n",
    "#  x_train.shape ( 19000, 32, 32, 3 )   \n",
    "# input_shape=x_train.shape[1:] (32, 32, 3) \n",
    "# mnist 와 비교하면 mnist 의 경우는 첫층이 완전연결계층이므로 \n",
    "# Flatten 시켜서  Flatten(input_shape=(28,28) ) 이렇게 입력했었고\n",
    "# Convolution 층은 이미지의 형상이 무시되지 않도록 입력해야하기 때문에 \n",
    "# (32, 32, 3)  이렇게 3차원으로 넣어야한다. \n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "# 모델 설정 \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " \n",
    "# 데이터 정규화 \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    " \n",
    "# 모델 학습 \n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=batch_size)\n",
    " \n",
    "# 모델 평가 \n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "#[0.3352026641368866, 0.9929999709129333]\n",
    "#    오차                        정확도 \n",
    "\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    " \n",
    "save_model(model, \"D:\\\\data\\\\leafs\\\\leaf.h5\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
